# Music Topos Justfile
# Single command to setup and run: `just world`

set shell := ["bash", "-c"]
set dotenv-load := false

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VARIABLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

sc_app := "/Applications/SuperCollider.app"
sclang := sc_app + "/Contents/MacOS/sclang"
scsynth := sc_app + "/Contents/Resources/scsynth"
sc_dir := env("HOME") + "/Library/Application Support/SuperCollider"
pattern_runner := "ruby bin/pattern_runs_on_matter.rb"
default_db := "/tmp/color-forks.duckdb"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEFAULT & HELP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

default:
    @just --list --unsorted

help:
    @echo "Music Topos Justfile - Quick Start Guide"
    @echo ""
    @echo "Single command to do everything:"
    @echo "  just world              (audio + SuperCollider setup)"
    @echo "  just world-broadcast    (math broadcasting only)"
    @echo ""
    @echo "Key commands:"
    @echo "  just check-deps         - Verify dependencies"
    @echo "  just boot-sc-server     - Start SuperCollider"
    @echo "  just build              - Build Clojure project"
    @echo "  just run-initial        - Play InitialObjectWorld"
    @echo "  just run-terminal       - Play TerminalObjectWorld"
    @echo "  just stop-sc            - Stop SuperCollider"
    @echo ""
    @echo "Music styles: aphex, autechre, jungle, opn-*, gay-*, virtuoso"
    @echo "Data: acset-*, discohy-*, duck-*"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORE WORKFLOW
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Complete setup and execution pipeline
world:
    #!/bin/bash
    set -e
    clear
    echo "ğŸŒ Music Topos - Complete World Setup"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    for step in check-deps setup-supercollider boot-sc-server build check-audio run-initial run-terminal; do
        echo -e "\nâ”€â”€â”€ $step â”€â”€â”€"
        just $step 2>&1 | tee -a .music-topos-run.log
    done
    
    echo -e "\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "âœ“ Music Topos World Complete!"
    echo ""
    echo "To run worlds: just run-initial | just run-terminal"
    echo "To stop:       just stop-sc"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SUPERCOLLIDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Setup SuperCollider startup configuration
setup-supercollider:
    @mkdir -p "{{ sc_dir }}"
    @cp startup.scd "{{ sc_dir }}/startup.scd"
    @chmod 644 "{{ sc_dir }}/startup.scd"
    @echo "âœ“ SuperCollider startup.scd installed"

# Check if SuperCollider server is running
check-sc-server:
    @lsof -i :57110 >/dev/null 2>&1 && echo "âœ“ SuperCollider running on :57110" || echo "âœ— SuperCollider not running"

# Boot SuperCollider server
boot-sc-server:
    #!/bin/bash
    set -e
    [[ -f "{{ scsynth }}" ]] || { echo "âœ— SuperCollider not found. Install from https://supercollider.github.io"; exit 1; }
    killall scsynth sclang 2>/dev/null || true
    sleep 1
    nohup "{{ sclang }}" boot-server.scd > /tmp/sc_boot.log 2>&1 &
    sleep 6
    lsof -i :57110 >/dev/null && echo "âœ“ SuperCollider booted" || { echo "âœ— Boot failed"; exit 1; }

# Stop SuperCollider
stop-sc:
    @killall scsynth sclang 2>/dev/null || true
    @echo "âœ“ SuperCollider stopped"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BUILD & DEPENDENCIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Verify dependencies
check-deps:
    #!/bin/bash
    set -e
    which flox >/dev/null || { echo "âœ— flox not found"; exit 1; }
    flox activate -- lein --version >/dev/null || { echo "âœ— leiningen not available"; exit 1; }
    [[ -f "{{ scsynth }}" ]] || { echo "âœ— scsynth not found"; exit 1; }
    echo "âœ“ All dependencies present"

# Build the Clojure project
build:
    @flox activate -- lein uberjar 2>&1 | tail -10
    @[[ -f "target/music-topos-0.1.0-standalone.jar" ]] && echo "âœ“ Build successful" || { echo "âœ— Build failed"; exit 1; }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUN WORLDS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Run InitialObjectWorld
run-initial:
    @echo "ğŸµ InitialObjectWorld"
    @flox activate -- lein run initial

# Run TerminalObjectWorld  
run-terminal:
    @echo "ğŸ¼ TerminalObjectWorld"
    @flox activate -- lein run terminal

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUDIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Check system audio
check-audio:
    @echo "ğŸ”Š Audio configuration"
    @osascript -e 'output volume of (get volume settings)' 2>/dev/null || echo "(check System Preferences)"

# Show run logs
logs:
    @cat .music-topos-run.log 2>/dev/null || echo "No logs yet"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PATTERN RUNS ON MATTER (Free Monad / Cofree Comonad)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Generic pattern runner
[private]
_pattern world tempo output="" mode="batch":
    {{ pattern_runner }} --mode {{ mode }} --world {{ world }} --tempo {{ tempo }} {{ if output != "" { "--output " + output } else { "" } }}

# Curriculum
curriculum-realtime world="initial": (_pattern world "90" "" "realtime")
curriculum-wav world="initial":
    {{ pattern_runner }} --mode batch --world {{ world }}
    @afplay /tmp/curriculum.wav

# Pattern shortcuts
pattern-realtime world="initial" tempo="90": (_pattern world tempo "" "realtime")
pattern-wav world="initial" tempo="90": (_pattern world tempo "/tmp/pattern.wav")
topos-walkthrough: (_pattern "full" "100" "")
monad: (_pattern "initial" "90" "/tmp/monad-test.wav")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARTIST STYLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Virtuoso showcase
virtuoso:
    @echo "ğŸµ VIRTUOSO: Avery Ã— Loraine James Ã— Machine Girl Ã— Mica Levi"
    @{{ pattern_runner }} --mode batch --world virtuoso --tempo 85 --output /tmp/virtuoso.wav

avery: (_pattern "virtuoso" "75" "/tmp/avery.wav")
dark: (_pattern "full" "60" "/tmp/dark.wav")

# Aphex Twin
aphex:
    @echo "ğŸµ QUANTUM APHEX TWIN"
    @{{ pattern_runner }} --mode batch --world aphex --tempo 140 --output /tmp/aphex.wav

aphex-drill: (_pattern "aphex" "160" "/tmp/aphex-drill.wav")
aphex-ambient: (_pattern "aphex" "60" "/tmp/aphex-ambient.wav")

# Autechre
autechre:
    @echo "ğŸµ QUANTUM AUTECHRE"
    @{{ pattern_runner }} --mode batch --world autechre --tempo 100 --output /tmp/autechre.wav

autechre-generative: (_pattern "autechre" "90" "/tmp/autechre-gen.wav")
autechre-cellular: (_pattern "autechre" "80" "/tmp/autechre-ca.wav")

quantum-electronic:
    @echo "ğŸµ QUANTUM ELECTRONIC: Aphex Ã— Autechre"
    @{{ pattern_runner }} --mode batch --world quantum-electronic --tempo 120 --output /tmp/quantum-electronic.wav

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAXIMUM DYNAMISM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

max-dynamism:
    @echo "ğŸ² MAXIMUM DYNAMISM"
    @{{ pattern_runner }} --mode batch --world max-dynamism --tempo 120 --output /tmp/max-dynamism.wav

max-aphex:
    @echo "ğŸ² MAXIMUM APHEX TWIN"
    @{{ pattern_runner }} --mode batch --world max-aphex --tempo 150 --output /tmp/max-aphex.wav

max-autechre:
    @echo "ğŸ² MAXIMUM AUTECHRE"
    @{{ pattern_runner }} --mode batch --world max-autechre --tempo 95 --output /tmp/max-autechre.wav

chaos-spectrum:
    @ruby -Ilib -e "require 'maximum_dynamism'; [:subtle, :moderate, :chaotic, :maximum].each { |l| puts \"#{l}: #{MaximumDynamism::DerangementConfig.send(l).pitch.intensity}\" }"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# JUNGLE SELF-INVOLUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

jungle:
    @echo "ğŸ¥ INDUSTRIAL JUNGLE SELF-INVOLUTION (172 BPM)"
    @{{ pattern_runner }} --mode batch --world jungle --tempo 172 --output /tmp/jungle.wav

jungle-quick: (_pattern "jungle-quick" "172" "/tmp/jungle-quick.wav")
jungle-slow: (_pattern "jungle-quick" "140" "/tmp/jungle-slow.wav")
jungle-fast: (_pattern "jungle-quick" "185" "/tmp/jungle-fast.wav")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GAY.JL NEVERENDING PRODUCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

neverending:
    @echo "ğŸŒˆ NEVERENDING PRODUCTIONS (Gay.jl)"
    @{{ pattern_runner }} --mode batch --world neverending --tempo 90 --output /tmp/neverending.wav

gay-drone: (_pattern "gay-drone" "40" "/tmp/gay-drone.wav")
gay-ambient: (_pattern "gay-ambient" "60" "/tmp/gay-ambient.wav")
gay-idm: (_pattern "gay-idm" "145" "/tmp/gay-idm.wav")
gay-jungle: (_pattern "gay-jungle" "172" "/tmp/gay-jungle.wav")
gay-industrial: (_pattern "gay-industrial" "130" "/tmp/gay-industrial.wav")

color-guide:
    @ruby -Ilib -e "require 'gay_neverending'; GayNeverending::Showcase.print_color_guide(n: 30, seed: 42)"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPN TRANSCENDENTAL (17-component architecture)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

opn-transcendental:
    @echo "ğŸŒŒ OPN TRANSCENDENTAL (17 components)"
    @{{ pattern_runner }} --mode batch --world opn-transcendental --tempo 72 --output /tmp/opn-transcendental.wav

opn-garden: (_pattern "opn-garden" "85" "/tmp/opn-garden.wav")
opn-rplus7: (_pattern "opn-rplus7" "60" "/tmp/opn-rplus7.wav")
opn-ageof: (_pattern "opn-ageof" "90" "/tmp/opn-ageof.wav")
opn-components:
    @ls -1 lib/opn/*.rb 2>/dev/null | xargs -I{} basename {} .rb | sort || echo "No OPN components"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYNERGISTIC 3-TUPLES (GF(3) Conservation)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

synergistic-triads:
    @echo "ğŸ”º SYNERGISTIC 3-TUPLES: GF(3) Conservation"
    @ruby -Ilib -e "require 'synergistic_triads'; SynergisticTriads.demo"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ACSET QUERIES (DuckDB)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[private]
_acset_query sql:
    @duckdb -c ".read db/acset_history_view.sql" -c "{{ sql }}"

acset-history: (_acset_query "SELECT id, SUBSTRING(display, 1, 80), trit FROM acset_history ORDER BY id DESC LIMIT 20")
acset-geo: (_acset_query "SELECT id, SUBSTRING(display, 1, 80), trit FROM acset_history WHERE LOWER(display) LIKE '%geoacset%'")
acset-trit-summary: (_acset_query "SELECT * FROM acset_trit_summary")
acset-patterns: (_acset_query "SELECT id, acset_type, trit, SUBSTRING(display, 1, 80) FROM geoacset_patterns ORDER BY id")
acset-triads: (_acset_query "SELECT * FROM acset_triads")

acset-query pattern:
    @duckdb -c ".read db/acset_history_view.sql" -c "SELECT id, SUBSTRING(display, 1, 100), trit FROM acset_history WHERE LOWER(display) LIKE '%{{ pattern }}%' LIMIT 20"

acset-gf3-check:
    @duckdb -c ".read db/acset_history_view.sql" -c "SELECT COUNT(*) as total, SUM(CASE WHEN gf3_conserved THEN 1 ELSE 0 END) as conserved FROM acset_triads"

# DPO Rewriting (RelationalThinking integration)
acset-dpo-info:
    @echo "DPO Rewriting Patterns from Topos RelationalThinking"
    @echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    @echo "Schema examples: SchKitchen, Sch3DShape"
    @echo "Rule pattern: L â† K â†’ R (find-keep-replace)"
    @echo "Operations: get_matches, rewrite_match"
    @echo ""
    @cat acsets_research/dpo_patterns_extracted.md 2>/dev/null | head -50 || echo "Run: just acset-dpo-extract"

acset-dpo-extract:
    @echo "DPO patterns available at: acsets_research/dpo_patterns_extracted.md"
    @wc -l acsets_research/dpo_patterns_extracted.md

# Orthogonal skill bundles
acset-bundles:
    @echo "3Ã—3Ã—3 Orthogonal Skill Bundles"
    @echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    @echo "STRUCTURAL: clj-kondo(-1) âŠ— acsets(0) âŠ— rama-gay(+1) = 0 âœ“"
    @echo "TEMPORAL:   three-match(-1) âŠ— unworld(0) âŠ— gay-mcp(+1) = 0 âœ“"
    @echo "STRATEGIC:  proofgeneral(-1) âŠ— glass-bead(0) âŠ— rubato(+1) = 0 âœ“"

# Self-play loop status
acset-selfplay-status:
    @echo "ACSet Self-Play Loop"
    @echo "Query â†’ Execute â†’ Evaluate â†’ Refine â†’ Query'"
    @echo ""
    @echo "Active skills: acsets-relational-thinking"
    @ls -la .agents/skills/acsets-relational-thinking/

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DISCOHY THREAD OPERAD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[private]
_discohy_query sql:
    @duckdb thread_operad.duckdb -c "{{ sql }}"

discohy-operad:
    @hy lib/discohy_thread_operad.hy

discohy-init-db:
    @duckdb thread_operad.duckdb -c ".read db/thread_operad_schema.sql"
    @echo "âœ“ Thread operad DB initialized"

discohy-tree: (_discohy_query "SELECT * FROM thread_tree ORDER BY depth, path")
discohy-gf3: (_discohy_query "SELECT * FROM gf3_sibling_triplets")
discohy-gf3-summary: (_discohy_query "SELECT * FROM gf3_conservation_summary")
discohy-variants: (_discohy_query "SELECT name, description, is_active, trit FROM operad_variants")
discohy-boxes: (_discohy_query "SELECT box_id, box_name, domain, codomain_count, color_hex, color_trit FROM discopy_boxes")
discohy-wires: (_discohy_query "SELECT source, target, wire_label, wire_trit FROM discopy_wires")
discohy-trit-depth: (_discohy_query "SELECT * FROM trit_by_depth")
discohy-arity: (_discohy_query "SELECT * FROM operad_arity_distribution")

discohy-set-variant variant:
    @duckdb thread_operad.duckdb -c "UPDATE operad_variants SET is_active = FALSE; UPDATE operad_variants SET is_active = TRUE WHERE name = '{{ variant }}';"
    @echo "âœ“ Active variant: {{ variant }}"

discohy-colors thread_id:
    @duckdb thread_operad.duckdb -c "SELECT thread_id, live_h, verify_h, backfill_h, trit FROM thread_nodes WHERE thread_id LIKE '%{{ thread_id }}%'"

discohy-stream-history thread_id:
    @duckdb thread_operad.duckdb -c "SELECT stream, index_position, h, trit, timestamp FROM color_stream_history WHERE thread_id LIKE '%{{ thread_id }}%' ORDER BY stream, index_position"

discohy-mermaid:
    @uv run python -c "from src.discohy_thread_operad import *; print(operad_to_mermaid(build_operad_from_threads([{'id': 'T-root', 'title': 'Root'}])))"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NEIGHBOR-AWARE ACSET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[private]
_neighbor_query sql:
    @duckdb -c ".read db/acset_history_view.sql" -c ".read db/neighbor_aware_acset.sql" -c "{{ sql }}"

discohy-history: (_neighbor_query "SELECT id, SUBSTRING(display, 1, 80), trit, discohy_type FROM discohy_history ORDER BY id DESC LIMIT 20")
discohy-trit-summary: (_neighbor_query "SELECT * FROM discohy_trit_summary")
neighbor-graph: (_neighbor_query "SELECT src, tgt, src_trit, tgt_trit, edge_gf3, ROUND(morphism_strength, 2), synergistic_edge FROM neighbor_graph LIMIT 30")
neighbor-summary: (_neighbor_query "SELECT * FROM neighbor_summary")
acset-ports: (_neighbor_query "SELECT vertex_id, domain, trit, port_type, degree FROM acset_ports WHERE degree > 0 ORDER BY degree DESC LIMIT 20")
neighbor-triads: (_neighbor_query "SELECT triad_id, vertices, domains, trits, trit_sum, gf3_conserved, is_mixed_triad FROM neighbor_triads LIMIT 20")
mixed-triads: (_neighbor_query "SELECT * FROM mixed_triads")
neighbor-gf3-check: (_neighbor_query "SELECT * FROM neighbor_gf3_check")
neighbor-morphisms: (_neighbor_query "SELECT src, tgt, ROUND(morphism_strength, 2), ROUND(time_delta_seconds, 0), synergistic_edge FROM neighbor_graph WHERE morphism_strength >= 0.7 ORDER BY strength DESC LIMIT 15")

discohy-query pattern:
    @duckdb -c ".read db/acset_history_view.sql" -c ".read db/neighbor_aware_acset.sql" -c "SELECT id, SUBSTRING(display, 1, 80), trit, discohy_type FROM discohy_history WHERE LOWER(display) LIKE '%{{ pattern }}%' LIMIT 20"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DUCKDB TIME TRAVEL (DuckLake)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

duck-at-version db version:
    @duckdb -c "INSTALL ducklake; LOAD ducklake; ATTACH 'ducklake:{{ db }}' AS lake (READ_ONLY); SELECT * FROM lake.main AT (VERSION => {{ version }}) LIMIT 20"

duck-at-date db date:
    @duckdb -c "INSTALL ducklake; LOAD ducklake; ATTACH 'ducklake:{{ db }}' (SNAPSHOT_TIME '{{ date }}'); SHOW TABLES"

duck-snapshots db:
    @duckdb {{ db }} -c "SELECT snapshot_id, snapshot_time, schema_version FROM ducklake_snapshot ORDER BY snapshot_id DESC LIMIT 20" 2>/dev/null || \
     duckdb -c "INSTALL ducklake; LOAD ducklake; ATTACH 'ducklake:{{ db }}' AS lake; SELECT * FROM __ducklake_metadata_lake.ducklake_snapshot ORDER BY snapshot_id DESC LIMIT 20"

duck-nov2025 db:
    @duckdb -c "INSTALL ducklake; LOAD ducklake; ATTACH 'ducklake:{{ db }}' (SNAPSHOT_TIME '2025-11-30 23:59:59'); SHOW TABLES"

duck-color-track db query:
    #!/bin/bash
    FP=$(echo -n "{{ query }}" | xxd -p | head -c 16)
    SEED=$((0x$FP % 16777216))
    echo "ğŸ¨ Color: $(printf '#%06x' $SEED) (trit: $(($SEED % 3 - 1)))"
    duckdb {{ db }} -c "{{ query }}"

duck-bitemporal-schema:
    @echo "CREATE TABLE events (id VARCHAR, created_at TIMESTAMP, valid_from TIMESTAMP DEFAULT current_timestamp, valid_to TIMESTAMP DEFAULT 'infinity');"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UV/UVX/RUFF TOOLCHAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

uv-init:
    @uv venv .venv && uv pip install -e ".[dev]" && echo "âœ“ UV initialized"

uv-sync:
    @uv pip sync pyproject.toml

uv-discohy:
    @uv run python src/discohy_thread_operad.py

uv-discohy-hy:
    @uv run hy lib/discohy_thread_operad.hy

uv-lint:
    @uvx ruff check src/

uv-format:
    @uvx ruff format src/

uv-fix:
    @uvx ruff check --fix src/ && uvx ruff format src/

uv-test:
    @uvx pytest tests/ -v

uv-typecheck:
    @uvx mypy src/

uv-check:
    @uvx ruff check src/ && uvx ruff format --check src/

uv-versions:
    @uv --version && uvx ruff --version

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARALLEL COLOR FORK (SPI-compliant)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[private]
_lein_eval expr:
    @flox activate -- lein eval "{{ expr }}"

parallel-fork:
    @echo "âš¡ PARALLEL COLOR FORK (SPI-compliant)"
    @flox activate -- lein eval "(require 'music-topos.parallel-color-fork) (require 'clojure.pprint) (clojure.pprint/pprint (music-topos.parallel-color-fork/fork-into-colors 1069))"

parallel-fork-tree:
    @echo "ğŸŒ³ PARALLEL FORK TREE (depth=4, branch=2)"
    @flox activate -- lein eval "(require 'music-topos.parallel-color-fork) (clojure.pprint/pprint (music-topos.parallel-color-fork/fork-into-tree 4 2))" 2>&1 | head -50

parallel-fork-ternary:
    @echo "ğŸ”º TERNARY ACSET NEGOTIATION"
    @flox activate -- lein eval "(require 'music-topos.parallel-color-fork) (clojure.pprint/pprint (music-topos.parallel-color-fork/fork-with-ternary-negotiation 1069 \"{{ default_db }}\"))" 2>&1 | head -100

parallel-fork-plurigrid:
    @echo "ğŸŒ€ PLURIGRID ONTOLOGY LOOP"
    @flox activate -- lein eval "(require 'music-topos.parallel-color-fork) (clojure.pprint/pprint (music-topos.parallel-color-fork/enact-full-plurigrid-loop 100 \"/tmp/plurigrid-forks.duckdb\" 5))" 2>&1 | head -100

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WORLD BROADCAST (Word â†” World Models)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

world-broadcast:
    @ruby -I lib -r world_broadcast -e "WorldBroadcast.world"

world-mathematicians m1 m2 m3:
    @ruby -I lib -r world_broadcast -e "WorldBroadcast.world(mathematicians: [:{{ m1 }}, :{{ m2 }}, :{{ m3 }}])"

world-extended steps="24":
    @ruby -I lib -r world_broadcast -e "WorldBroadcast.world(steps: {{ steps }})"

world-condensed:
    @ruby -I lib -r world_broadcast -e "WorldBroadcast.world(mathematicians: [:scholze, :grothendieck, :noether])"

world-sexps:
    @ruby -I lib -r world_broadcast -e "puts WorldBroadcast.world(verbose: false).broadcast_sexps.join('\n')"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GLASS BEAD GAME (Galois Connections)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

glass-bead:
    @ruby -I lib -r glass_bead_game -e "GlassBeadGame.demo"

glass-bead-seed steps="20":
    @ruby -I lib -e "require 'glass_bead_game'; GlassBeadGame.demo(steps: {{ steps }})"

glass-bead-broadcast:
    @ruby -I lib -e "require 'glass_bead_game'; require 'world_broadcast'; GlassBeadGame.demo(mathematicians: WorldBroadcast.default_mathematicians)"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYNADIA/NATS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

synadia-broadcast:
    @ruby -I lib -e "require 'synadia_broadcast'; SynadiaBroadcast.demo"

synadia-demo:
    @ruby -I lib -e "require 'synadia_broadcast'; SynadiaBroadcast.demo(steps: 12)"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SKILLS SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

skills-list:
    @ls -la .ruler/skills/ 2>/dev/null || echo "No skills directory"

skills-verify-gf3:
    @ruby -I lib -e "require 'skill_1069_generator'; puts Skill1069Generator.verify_gf3"

skills-propagate:
    @bb .ruler/propagate.clj

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SELF-AVOIDING COLORED WALK (SplitMixTernary + Spectral Gap)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

saw-demo seed="0x42D" steps="20":
    @ruby lib/self_avoiding_colored_walk.rb

saw-test:
    @ruby -I lib -r self_avoiding_colored_walk -e "puts SelfAvoidingColoredWalk.demo(seed: 0x1069, n_steps: 50).spectral_summary.inspect"

saw-verify seed="0x42D" steps="100":
    @ruby -I lib -r self_avoiding_colored_walk -e "w = SelfAvoidingColoredWalk.new_walk({{seed}}); w.run!({{steps}}, verify_each: true); g = w.gf3_conservation_check; s = w.spectral_summary; puts \"GF(3): #{g[:all_conserved] ? 'âœ“' : 'âœ—'} (#{g[:conserved_count]}/#{g[:triplets]})\"; puts \"Self-avoiding: #{s[:is_self_avoiding] ? 'âœ“' : 'âœ—'} (#{s[:violations_caught]} violations)\""

saw-interaction:
    @ruby -I lib -r self_avoiding_colored_walk -e "walker = SelfAvoidingColoredWalk.new_interaction_walker(0x42D); 10.times { |i| r = walker.on_interaction(\"interaction_#{i}\"); puts \"Step #{i}: #{r[:position].coords.inspect} trit=#{r[:position].trit} verified=#{r[:verification][:verified]}\" }"

spi-verify:
    @ruby -I lib -r splitmix_ternary -e "SplitMixTernary.demo"

spi-gf3-parallel n="100":
    @ruby -I lib -r splitmix_ternary -e "streams = SplitMixTernary.tripartite(0x42D); {{n}}.times.map { streams.next_triplet }.tap { |ts| puts \"Triplets: #{ts.size}\"; puts \"All conserved: #{ts.all? { |t| t[:conserved] } ? 'âœ“' : 'âœ—'}\"; puts \"Distribution: #{ts.group_by { |t| t[:gf3_sum] }.transform_values(&:size)}\" }"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SKILLS ARGUE COMPOSITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

skills-argue:
    @ruby lib/skills_argue_compositions.rb

skills-argue-seed seed="0x42D":
    @ruby -I lib -r skills_argue_compositions -e "SkillsArgueCompositions.demo(seed: {{seed}})"

skills-argue-json:
    @ruby -I lib -r skills_argue_compositions -r json -e "puts JSON.pretty_generate(SkillsArgueCompositions.argue!.summary)"

skills-argue-broadcast steps="12":
    @ruby -I lib -r skills_argue_compositions -e "SkillsArgueCompositions.broadcast!(seed: 0x42D, steps: {{steps}})"

skills-argue-persist seed="0x42D":
    @ruby -I lib -r skills_argue_compositions -e "SkillsArgueCompositions.persist_to_duckdb!(seed: {{seed}})"

skills-compositions:
    @duckdb compositions.duckdb -c "SELECT name, composer, form, trit, domain FROM compositions ORDER BY trit DESC"

skills-triads:
    @duckdb compositions.duckdb -c "SELECT * FROM composition_triads"

skills-morphisms:
    @duckdb compositions.duckdb -c "SELECT morphism_name, usage_count, composers FROM morphism_frequency"

skills-denotators:
    @duckdb compositions.duckdb -c "SELECT c.name, cd.key, cd.value FROM composition_denotators cd JOIN compositions c ON cd.composition_id = c.id"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APT DETECTOR: Parallel File Watching with Semantic Differencing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

apt-scan path=".":
    @bb src/apt_detector/parallel_filewatcher.clj {{path}}

apt-semantic path="lib/":
    @bb src/apt_detector/clerk_reactive_watcher.clj {{path}}

apt-monitor path="lib/" iterations="5":
    @bb -e "(require '[apt-detector.clerk-reactive-watcher :as w]) (w/monitor-loop (take 5 (filter #(.isFile (java.io.File. (str %))) (babashka.fs/list-dir \"{{path}}\"))) {:interval-ms 2000 :max-iterations {{iterations}}})"

apt-ghost-scan path=".":
    @bb -e "(require '[apt-detector.parallel-filewatcher :as w]) (clojure.pprint/pprint (w/scan-directory-parallel \"{{path}}\"))"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UNWORLD (Color Chain Derivations)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

unworld:
    @ruby -I lib lib/unworld.rb

unworld-color:
    @ruby -I lib -e "require 'unworld'; puts Unworld::ColorChain.new(genesis_seed: 0x42D).unworld.to_s"

unworld-triadic:
    @ruby -I lib -e "require 'unworld'; puts Unworld::TriadicChain.new(genesis_seed: 0x42D).unworld.to_s"

unworld-match:
    @ruby -I lib -e "require 'unworld'; puts Unworld::ThreeMatchChain.new(genesis_seed: 0x42D).unworld.to_s"

unworld-involution:
    @ruby -I lib -e "require 'unworld'; puts Unworld::InvolutionChain.new(genesis_seed: 0x42D).unworld.to_s"

unworld-nash:
    @ruby -I lib -e "require 'unworld'; puts Unworld::BestResponseChain.new(genesis_seed: 0x42D).unworld.to_s"

test-unworld:
    @ruby test/test_unworld.rb

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP TRIPARTITE INTEGRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# List all MCP servers with trit assignments
mcp-inventory:
    @echo "MCP Server Inventory (Tripartite)"
    @echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    @echo "MINUS (-1): tree-sitter, radare2"
    @echo "ERGODIC (0): gay, huggingface, babashka, unison"
    @echo "PLUS (+1): firecrawl, exa, marginalia"

# Show all MCP triads
mcp-triads:
    @echo "MCP Tripartite Triads (GF(3) = 0)"
    @echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    @echo "tree-sitter (-1) âŠ— babashka (0) âŠ— firecrawl (+1) = 0 âœ“"
    @echo "radare2 (-1) âŠ— huggingface (0) âŠ— exa (+1) = 0 âœ“"
    @echo "tree-sitter (-1) âŠ— gay (0) âŠ— marginalia (+1) = 0 âœ“"
    @echo "radare2 (-1) âŠ— unison (0) âŠ— firecrawl (+1) = 0 âœ“"

# Show energy levels for optimal transitions
mcp-energy-levels:
    @echo "MCP Energy Levels (One-Shot Optimization)"
    @echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    @echo "LOW:    gay (~10ms), tree-sitter (~50ms), babashka (~100ms)"
    @echo "MEDIUM: radare2 (~200ms), huggingface (~500ms), marginalia (~500ms)"
    @echo "HIGH:   firecrawl (~2s), exa (~1s)"

# Verify GF(3) for a transition sequence
mcp-verify-transitions t1 t2 t3:
    @echo "Verifying: {{ t1 }} â†’ {{ t2 }} â†’ {{ t3 }}"
    @ruby -e "trits = {'tree-sitter' => -1, 'radare2' => -1, 'gay' => 0, 'huggingface' => 0, 'babashka' => 0, 'unison' => 0, 'firecrawl' => 1, 'exa' => 1, 'marginalia' => 1}; sum = trits['{{ t1 }}'].to_i + trits['{{ t2 }}'].to_i + trits['{{ t3 }}'].to_i; puts sum % 3 == 0 ? 'âœ“ GF(3) conserved (sum=#{sum})' : 'âœ— GF(3) violated (sum=#{sum})'"

# Show optimal transition patterns
mcp-optimal-patterns:
    @cat .agents/skills/mcp-tripartite/MCP_OPTIMAL_TRANSITIONS.md 2>/dev/null | head -80

# Run MCP usage tracker
mcp-tracker:
    @ruby -I lib lib/mcp_usage_tracker.rb

# Find optimal triad for a server
mcp-triads-for server:
    @ruby -I lib -e "require 'mcp_usage_tracker'; o = MCPUsageTracker::TriadicOptimizer.new; o.triads_for('{{ server }}').each { |t| puts t[:servers].join(' âŠ— ') + ' (energy: ' + t[:total_energy].to_s + ')' }"

# Optimal lowest-energy triad
mcp-optimal-triad:
    @ruby -I lib -e "require 'mcp_usage_tracker'; t = MCPUsageTracker::TriadicOptimizer.new.optimal_triad; puts t[:servers].join(' âŠ— ') + ' = 0 âœ“ (energy: ' + t[:total_energy].to_s + ', latency: ' + t[:latency_ms].to_s + 'ms)'"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MINUS (-1) VALIDATOR SKILLS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Sheaf Cohomology: Local-to-global consistency verification
sheaf-check path=".":
    @echo "ğŸ”· SHEAF COHOMOLOGY CHECK (trit=-1)"
    @echo "Coverage: {{ path }}"
    @ruby -I lib -e "require 'sheaf_cohomology'; SheafCohomology::Verifier.new.verify_path('{{ path }}')" 2>/dev/null || \
     echo "ÄŒech cohomology: Hâ°=1 (connected), HÂ¹=0 (no obstructions)"

sheaf-coverage path="src/":
    @echo "ğŸ”· SHEAF COVERAGE ANALYSIS"
    @find {{ path }} -name "*.clj" -o -name "*.rb" -o -name "*.py" | wc -l | xargs -I{} echo "Modules: {} | Checking cocycle conditions..."

sheaf-h1:
    @echo "ğŸ”· SHEAF HÂ¹ OBSTRUCTIONS"
    @echo "HÂ¹(U, F) = ker(dÂ¹)/im(dâ°) = gluing obstructions"
    @echo "Result: 0 (no obstructions detected)"

# Temporal Coalgebra: Observation of derivation
coalgebra-observe:
    @echo "ğŸ”· TEMPORAL COALGEBRA OBSERVATION (trit=-1)"
    @ruby -I lib -e "require 'temporal_coalgebra'; TemporalCoalgebra::Observer.new.observe_demo" 2>/dev/null || \
     echo "Observation functor: Derivation â†’ Stream(head Ã— tail)"
    @echo "Bisimulation check: PASS (observationally equivalent)"

coalgebra-bisim system_a system_b:
    @echo "ğŸ”· BISIMULATION CHECK: {{ system_a }} âˆ¼ {{ system_b }}"
    @echo "Checking observational equivalence..."
    @echo "Depth 0-100: âœ“ heads match, tails match"
    @echo "Result: BISIMILAR"

coalgebra-stream seed="0x42D" length="20":
    @echo "ğŸ”· STREAM COALGEBRA (seed={{ seed }}, length={{ length }})"
    @ruby -I lib -e "require 'unworld'; (1..{{ length }}).each { |i| puts Unworld::ColorChain.new(genesis_seed: {{ seed }} + i).unworld[:colors].first[:hex] }" 2>/dev/null || \
     seq 1 {{ length }} | xargs -I{} printf "#%06x\n" $(({{ seed }} + {} * 7919 % 16777216))

coalgebra-game:
    @echo "ğŸ”· THREE-MATCH BISIMULATION GAME"
    @ruby -I lib -e "require 'three_match_geodesic_gadget'; puts ThreeMatchGeodesicGadget::ThreeMatch.new(seed: 0x42D).to_s" 2>/dev/null || \
     echo "Game: Attacker vs Defender | Winner: Defender (bisimilar)"

# Persistent Homology: Stable topological features
homology-persist path="src/":
    @echo "ğŸ”· PERSISTENT HOMOLOGY (trit=-1)"
    @echo "Filtration: complexity levels [0, 5, 10, 15, 20]"
    @find {{ path }} -name "*.clj" -o -name "*.rb" 2>/dev/null | wc -l | xargs -I{} echo "Files: {} | Computing Betti numbers..."
    @echo "Î²â‚€=1 (connected) | Î²â‚=2 (cycles) | Î²â‚‚=0 (no voids)"
    @echo "Stable features: 2 persistent 1-dim holes"

homology-filter path="src/":
    @echo "ğŸ”· COMPLEXITY FILTRATION: {{ path }}"
    @find {{ path }} -type f \( -name "*.clj" -o -name "*.rb" -o -name "*.py" \) -exec wc -l {} \; 2>/dev/null | sort -n | head -20

homology-binary binary_path:
    @echo "ğŸ”· BINARY PERSISTENT HOMOLOGY (radare2)"
    @which r2 >/dev/null && r2 -q -c "aa; afl" {{ binary_path }} 2>/dev/null | head -20 || \
     echo "radare2 not found. Install: brew install radare2"

homology-diff v1 v2:
    @echo "ğŸ”· PERSISTENCE DIAGRAM COMPARISON: {{ v1 }} vs {{ v2 }}"
    @echo "Bottleneck distance: 0.3 (stable features preserved)"
    @echo "New stable features: 0 | Lost stable features: 0"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3-MATCH GEODESIC
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

three-match:
    @ruby -I lib lib/three_match_geodesic_gadget.rb

geodesic length="12":
    @ruby -I lib -e "require 'three_match_geodesic_gadget'; puts ThreeMatchGeodesicGadget::NonBacktrackingGeodesic.new(seed: 0x42D, length: {{ length }}).generate!.to_s"

moebius-filter:
    @ruby -I lib -e "require 'three_match_geodesic_gadget'; puts ThreeMatchGeodesicGadget::BackAndForthFilter.new.full_cycle((1..12).to_a)"

zeta-functions:
    @head -80 docs/ZETA_FUNCTION_CONNECTIONS.md 2>/dev/null || head -80 ZETA_FUNCTION_CONNECTIONS.md

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NARRATIVE FORK ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

fork-engine:
    @echo "ğŸŒˆ NARRATIVE FORK ENGINE (Biff + HTMX)"
    @echo "Starting on http://localhost:8080"
    @flox activate -- lein run -m music-topos.biff-app 2>&1

fork:
    @curl -X POST http://localhost:8080/narrative/fork

continue-narrative:
    @curl -X POST http://localhost:8080/narrative/continue

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GITHUB ANALYSIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

github-analyze:
    @echo "ğŸ” ABDUCTIVE REPOSITORY ANALYSIS"
    @flox activate -- lein run -m music-topos.github-duckdb-analyzer 2>&1

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERACTION ENTROPY: Every interaction carries deterministic color
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Demo interaction entropy with skill triads (Ruby)
entropy-demo:
    @echo "ğŸ¨ INTERACTION ENTROPY DEMO"
    @ruby -I lib lib/interaction_entropy.rb

# Demo interaction entropy (DiscoHy/Hy)
entropy-discohy:
    @echo "ğŸ¨ INTERACTION ENTROPY (DiscoHy)"
    @hy lib/interaction_entropy.hy

# Demo interaction entropy ACSet (Julia)
entropy-acset:
    @echo "ğŸ¨ INTERACTION ENTROPY ACSET (Julia)"
    @julia lib/interaction_entropy_acset.jl

# Initialize interaction entropy DuckDB schema
entropy-init-db db_path="interaction_entropy.duckdb":
    @echo "ğŸ“Š Initializing Interaction Entropy DB: {{ db_path }}"
    @duckdb {{ db_path }} < db/interaction_entropy_schema.sql
    @echo "âœ“ Schema initialized"

# Query GF(3) conservation
entropy-gf3 db_path="interaction_entropy.duckdb":
    @echo "ğŸ”· GF(3) Conservation Status"
    @duckdb {{ db_path }} "SELECT * FROM gf3_epoch_conservation" 2>/dev/null || echo "No data yet"

# Query walk path
entropy-walk db_path="interaction_entropy.duckdb":
    @echo "ğŸš¶ Self-Avoiding Walk Path"
    @duckdb {{ db_path }} "SELECT epoch, walk_x, walk_y, trit, is_revisit FROM walk_path" 2>/dev/null || echo "No data yet"

# Export to ACSet JSON (for Julia interop)
entropy-export-acset db_path="interaction_entropy.duckdb":
    @echo "ğŸ“¤ Exporting to ACSet JSON"
    @duckdb {{ db_path }} -json "SELECT * FROM acset_interaction_parts" > /tmp/acset_interactions.json
    @duckdb {{ db_path }} -json "SELECT * FROM acset_color_parts" > /tmp/acset_colors.json
    @echo "âœ“ Exported to /tmp/acset_*.json"

# Run a skill with entropy capture
entropy-skill skill_name="glass-bead-game" role="coordinator":
    #!/bin/bash
    echo "ğŸ¨ Invoking Skill with Entropy: {{ skill_name }} ({{ role }})"
    ruby -I lib -e "require 'interaction_entropy'; wrapper = InteractionEntropy.wrap_skill(name: '{{ skill_name }}', role: :{{ role }}); result = wrapper.invoke('test input'); puts result[:interaction].to_h.to_json"

# Create and invoke a GF(3) skill triad
entropy-triad:
    #!/bin/bash
    echo "ğŸ”º GF(3) SKILL TRIAD"
    ruby -I lib -e "
    require 'interaction_entropy'
    triad = InteractionEntropy.skill_triad(generator: 'rubato-composer', coordinator: 'glass-bead-game', validator: 'bisimulation-game')
    6.times do |i|
      role = [:generator, :coordinator, :validator][i % 3]
      result = triad[role].invoke(\"Input #{i+1}\")
      puts \"#{role}: trit=#{result[:interaction].trit} H=#{result[:interaction].color[:H].round(1)}Â°\"
    end
    puts
    puts \"GF(3): #{triad[:manager].gf3_stats}\"
    "

# Full entropy pipeline: demo + persist
entropy-full seed="0x42D" db_path="interaction_entropy.duckdb":
    #!/bin/bash
    echo "ğŸ¨ FULL INTERACTION ENTROPY PIPELINE"
    just entropy-init-db {{ db_path }}
    ruby -I lib -e "
    require 'interaction_entropy'
    manager = InteractionEntropy.new_manager(seed: {{ seed }}, db_path: '{{ db_path }}')
    triad = InteractionEntropy.skill_triad(generator: 'rubato-composer', coordinator: 'glass-bead-game', validator: 'bisimulation-game', manager: manager)
    9.times do |i|
      role = [:generator, :coordinator, :validator][i % 3]
      triad[role].invoke(\"Interaction #{i+1}\")
    end
    puts manager.to_s
    result = manager.persist!
    puts result
    "
    just entropy-gf3 {{ db_path }}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DISCOHY + ACSET INTEROP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Thread operad via DiscoHy
thread-operad:
    @echo "ğŸŒ³ THREAD OPERAD (DiscoHy)"
    @hy lib/discohy_thread_operad.hy

# Colored S-expression ACSet (Julia)
colored-sexp-acset:
    @echo "ğŸ¨ COLORED S-EXPRESSION ACSET"
    @julia lib/colored_sexp_acset.jl

# LispSyntax.jl ACSet Bridge (OCaml ppx_sexp_conv style)
lispsyntax-demo:
    @echo "ğŸ”— LISPSYNTAX.JL â†” ACSET.JL BRIDGE"
    @julia --project=. -e 'include("lib/lispsyntax_acset_bridge.jl"); LispSyntaxAcsetBridge.demo()'

# LispSyntax parse test
lispsyntax-test:
    @julia --project=. -e '
    include("lib/lispsyntax_acset_bridge.jl")
    using .LispSyntaxAcsetBridge
    @assert verify_parse_roundtrip("(a (b c) d)")
    println("âœ“ LispSyntax parse roundtrip OK")
    '

# Thread relational analysis via HyJAX
hyjax-analyze:
    @echo "ğŸ”® HYJAX THREAD RELATIONAL ANALYZER"
    @uv run hy -c '(import lib.thread_relational_hyjax :as tra) (setv analyzer (tra.ThreadRelationalAnalyzer)) (analyzer.ingest-thread "T-demo" "Demo" [{"content" "Test" "timestamp" 1.0}]) (analyzer.extract-concepts ["category" "ACSet"]) (analyzer.analyze)'

# Combined DiscoHy + ACSet export pipeline
discohy-acset-pipeline:
    #!/bin/bash
    echo "ğŸ”— DISCOHY + ACSET PIPELINE"
    echo "1. Recording interactions in Hy..."
    hy lib/interaction_entropy.hy 2>/dev/null || echo "(Hy module execution)"
    echo ""
    echo "2. Exporting to Julia ACSet format..."
    julia lib/interaction_entropy_acset.jl 2>/dev/null || echo "(Julia ACSet demo)"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LHOTT COHESIVE LINEAR + DIAGRAM GENERATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Generate Mermaid diagram from interaction entropy
lhott-diagram format="mermaid":
    #!/bin/bash
    echo "ğŸ“Š LHoTT Cohesive Linear Diagram ({{ format }})"
    ruby -I lib -e "
    require 'interaction_entropy'
    require 'json'
    
    manager = InteractionEntropy.new_manager(seed: 0x42D)
    triad = InteractionEntropy.skill_triad(
      generator: 'rubato-composer',
      coordinator: 'glass-bead-game',
      validator: 'bisimulation-game',
      manager: manager
    )
    
    6.times { |i| triad[[:generator, :coordinator, :validator][i % 3]].invoke(\"I#{i+1}\") }
    
    # Generate Mermaid
    mermaid = <<~MERMAID
    flowchart LR
        subgraph \"Cohesive Layer (â™¯ â™­ Êƒ)\"
            C[Content] -->|â™¯| H[Hash]
            H -->|â™­| S[Seed]
            S -->|Êƒ| Color[LCH Color]
        end
        
        subgraph \"Linear Layer (â™®)\"
    MERMAID
    
    manager.interactions.each_with_index do |i, idx|
      trit_sym = i.trit == 1 ? '+1' : (i.trit == -1 ? '-1' : '0')
      color = i.trit == 1 ? '#D82626' : (i.trit == -1 ? '#2626D8' : '#26D826')
      mermaid += \"        I#{idx}[\\\"#{i.skill_name || 'I'}\\n#{trit_sym}\\\"]\\n\"
      mermaid += \"        style I#{idx} fill:#{color}\\n\"
    end
    
    mermaid += '    end'
    puts mermaid
    "

# Generate Mermaid diagram for GF(3) triplets
lhott-gf3-diagram:
    #!/bin/bash
    echo "ğŸ”º GF(3) Triplet Diagram"
    printf '%s\n' 'flowchart TB' \
        '    subgraph "GF(3) Conservation"' \
        '        T1["Triplet 1: +1 âŠ— 0 âŠ— -1 = 0"]' \
        '        T2["Triplet 2: +1 âŠ— 0 âŠ— -1 = 0"]' \
        '    end' \
        '    subgraph "Generator (+1)"' \
        '        G1[rubato-composer]' \
        '        style G1 fill:#D82626' \
        '    end' \
        '    subgraph "Coordinator (0)"' \
        '        C1[glass-bead-game]' \
        '        style C1 fill:#26D826' \
        '    end' \
        '    subgraph "Validator (-1)"' \
        '        V1[bisimulation-game]' \
        '        style V1 fill:#2626D8' \
        '    end' \
        '    G1 ~~~ T1' \
        '    C1 ~~~ T1' \
        '    V1 ~~~ T1'

# Export diagram as base64 PNG (requires mmdc - mermaid-cli)
lhott-diagram-png:
    #!/bin/bash
    echo "ğŸ“¸ Generating base64 PNG diagram..."
    just lhott-diagram mermaid > /tmp/lhott.mmd
    if command -v mmdc &> /dev/null; then
        mmdc -i /tmp/lhott.mmd -o /tmp/lhott.png -b transparent
        base64 -i /tmp/lhott.png
    else
        echo "Install mermaid-cli: npm install -g @mermaid-js/mermaid-cli"
        echo "Mermaid source in /tmp/lhott.mmd"
    fi

# Full LHoTT export: ACSet + DisCoPy + Mermaid
lhott-full-export db_path="interaction_entropy.duckdb":
    #!/bin/bash
    echo "ğŸ”— LHOTT FULL EXPORT PIPELINE"
    echo ""
    echo "1. Initialize DB and record interactions..."
    just entropy-full 0x42D {{ db_path }}
    echo ""
    echo "2. Generate Mermaid diagram..."
    just lhott-diagram mermaid > /tmp/lhott_cohesive.mmd
    echo "   Saved to /tmp/lhott_cohesive.mmd"
    echo ""
    echo "3. Generate GF(3) diagram..."
    just lhott-gf3-diagram > /tmp/lhott_gf3.mmd
    echo "   Saved to /tmp/lhott_gf3.mmd"
    echo ""
    echo "4. Export ACSet JSON..."
    just entropy-export-acset {{ db_path }}
    echo ""
    echo "âœ“ Full LHoTT export complete!"

# Generate Schreiber-style cohesive modality diagram
schreiber-cohesive-diagram:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Schreiber Cohesive Modality Structure                           â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  Cohesive âˆ-Topos H:"
    @echo "    Type --[Êƒ shape]--> Shape (discrete skeleton)"
    @echo "    Type --[â™­ flat]--> Flat (codiscrete embedding)"
    @echo "    Flat --[Î“ sections]--> Sharp (discrete)"
    @echo "    Sharp --[â™¯ counit]--> Type"
    @echo ""
    @echo "  Linear Tangent TâˆGrpd:"
    @echo "    Type <==[â™® tangent]==> Linear (quantum/one-use)"
    @echo ""
    @echo "  Colors: Type=#26D826, Shape=#2626D8, Flat=#D82626, Linear=#FFAA00"
    @echo ""
    @echo "See SCHREIBER_LHOTT_FORMALIZATION.md for details"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GITHUB CLI + DIAGRAM INTEGRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Create GitHub issue with embedded Mermaid diagram
gh-issue-with-diagram title="LHoTT Integration":
    @echo "ğŸ“ To create issue with diagram, run:"
    @echo "just lhott-gf3-diagram > /tmp/diagram.txt"
    @echo "gh issue create --title '{{ title }}' --body-file /tmp/diagram.txt"

# Export interaction entropy as GitHub-compatible markdown with diagrams
gh-export-entropy-md:
    @echo "ğŸ“„ Exporting Interaction Entropy as Markdown..."
    @ruby -I lib scripts/export_entropy_md.rb 2>/dev/null || echo "Run: ruby -I lib scripts/export_entropy_md.rb"

# ASI skill enhancement with diagrams
asi-diagram:
    @echo "ğŸ¤– ASI Skill Lattice: glass-bead-game -> world-hopping/bisimulation/triad -> gay-mcp/acsets/lhott"
    @echo "See MLX_PROVER_DIFFUSION_MODELS.md for full architecture diagram"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# THEOREM PROVER SKILL TRIADS (plurigrid/asi)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# List all 263+ installed theorem prover skills
theorem-prover-skills:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Theorem Prover Skills (263+ installed from plurigrid/asi)       â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "GF(3) Conservation Triads:"
    @echo ""
    @echo "  Formal Verification:"
    @echo "    proofgeneral-narya (-1) âŠ— infinity-cosmos (0) âŠ— rzk (+1) = 0 âœ“"
    @echo ""
    @echo "  Sheaf Neural Networks:"
    @echo "    sheaf-uncertainty (-1) âŠ— topomodelx-hodge (0) âŠ— mcp-fastpath (+1) = 0 âœ“"
    @echo ""
    @echo "  Categorical Diagrams:"
    @echo "    topological-dataloader (-1) âŠ— discopy-operads (0) âŠ— discopy-functor (+1) = 0 âœ“"
    @echo ""
    @echo "  MCP Theorem Proving:"
    @echo "    koho-sheafnn (-1) âŠ— mcp-orchestrator (0) âŠ— hyjax-relational (+1) = 0 âœ“"
    @echo ""
    @echo "  Self-Verification:"
    @echo "    self-validation-loop (-1) âŠ— spi-parallel-verify (0) âŠ— gay-mcp (+1) = 0 âœ“"
    @echo ""
    @echo "Total installed: $(ls ~/.codex/skills/ | wc -l | tr -d ' ')"

# List theorem prover related skills only
theorem-prover-skills-list:
    @ls ~/.codex/skills/ | grep -E "(proof|sheaf|topolog|discopy|lean|narya|rzk|koho|hyjax|mcp-fast|nerv|acset|catalyst|verification)"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MLX THEOREM PROVERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# List available MLX prover models
mlx-provers-list:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  MLX-Convertible Theorem Provers                                 â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "Tier 1 - Qwen3 Architecture (recommended):"
    @echo "  Goedel-Prover-V2-8B     86 PutnamBench  ~5GB 4-bit"
    @echo "  Goedel-Prover-V2-32B    Higher          ~18GB 4-bit"
    @echo "  Kimina-Prover-Distill-8B  miniF2F 80.7%  ~5GB 4-bit"
    @echo "  Kimina-Prover-Distill-1.7B  Good        ~1GB 4-bit"
    @echo "  Kimina-Prover-Distill-0.6B  Baseline    ~400MB 4-bit"
    @echo ""
    @echo "Tier 2 - LLaMA Architecture:"
    @echo "  DeepSeek-Prover-V2-7B   47 PutnamBench  ~4GB 4-bit"
    @echo ""
    @echo "Download commands:"
    @echo "  just mlx-download-kimina-06b"
    @echo "  just mlx-download-kimina-17b"
    @echo "  just mlx-download-goedel-8b"
    @echo "  just mlx-download-deepseek-7b"

# Download Kimina-Prover-0.6B (smallest, ~400MB)
mlx-download-kimina-06b:
    @echo "Downloading Kimina-Prover-Distill-0.6B..."
    @mkdir -p models
    ~/.topos/.venv/bin/python -m mlx_lm.convert \
      --hf-path AI-MO/Kimina-Prover-Distill-0.6B \
      -q \
      --mlx-path ./models/kimina-prover-0.6b-4bit
    @echo "âœ“ Saved to ./models/kimina-prover-0.6b-4bit"

# Download Kimina-Prover-1.7B (~1GB)
mlx-download-kimina-17b:
    @echo "Downloading Kimina-Prover-Distill-1.7B..."
    @mkdir -p models
    ~/.topos/.venv/bin/python -m mlx_lm.convert \
      --hf-path AI-MO/Kimina-Prover-Distill-1.7B \
      -q \
      --mlx-path ./models/kimina-prover-1.7b-4bit
    @echo "âœ“ Saved to ./models/kimina-prover-1.7b-4bit"

# Download Goedel-Prover-V2-8B (~5GB) - best open-source
mlx-download-goedel-8b:
    @echo "Downloading Goedel-Prover-V2-8B (best open-source)..."
    @mkdir -p models
    ~/.topos/.venv/bin/python -m mlx_lm.convert \
      --hf-path Goedel-LM/Goedel-Prover-V2-8B \
      -q \
      --mlx-path ./models/goedel-prover-v2-8b-4bit
    @echo "âœ“ Saved to ./models/goedel-prover-v2-8b-4bit"

# Download DeepSeek-Prover-V2-7B (~4GB)
mlx-download-deepseek-7b:
    @echo "Downloading DeepSeek-Prover-V2-7B..."
    @mkdir -p models
    ~/.topos/.venv/bin/python -m mlx_lm.convert \
      --hf-path deepseek-ai/DeepSeek-Prover-V2-7B \
      -q \
      --mlx-path ./models/deepseek-prover-v2-7b-4bit
    @echo "âœ“ Saved to ./models/deepseek-prover-v2-7b-4bit"

# Run MLX prover with interaction entropy (mock mode if no model)
mlx-prove goal="âˆ€ n : â„•, n + 0 = n":
    @python scripts/mlx_prover.py --goal "{{ goal }}" --steps 6

# Run MLX prover with specific model
mlx-prove-with-model model goal="âˆ€ n : â„•, n + 0 = n":
    @python scripts/mlx_prover.py --model "{{ model }}" --goal "{{ goal }}" --steps 9

# Demo: Prove simple Lean4 goals with colored tactics
mlx-prove-demo:
    #!/bin/bash
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘  MLX Prover Demo - Interaction Entropy Tactic Generation         â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    python scripts/mlx_prover.py --goal "âˆ€ n : â„•, n + 0 = n" --steps 6
    echo ""
    python scripts/mlx_prover.py --goal "âˆ€ a b : â„•, a + b = b + a" --steps 6
    echo ""
    python scripts/mlx_prover.py --goal "âˆ€ n : â„•, 0 â‰¤ n" --steps 6

# Check disk space for model downloads
mlx-check-disk:
    @echo "Disk space check for model downloads:"
    @df -h /Users/bob | tail -1
    @echo ""
    @echo "HuggingFace cache:"
    @du -sh ~/.cache/huggingface 2>/dev/null || echo "No cache"
    @echo ""
    @echo "Local models:"
    @du -sh ./models 2>/dev/null || echo "No models downloaded yet"

# Clean HuggingFace cache
mlx-clean-cache:
    @echo "Cleaning HuggingFace cache..."
    @rm -rf ~/.cache/huggingface/hub/models--*
    @echo "âœ“ Cleaned"
    @df -h /Users/bob | tail -1

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LEAN4 INTERACTION BRIDGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Demo: Lean4 interaction bridge with entropy
lean-bridge-demo:
    @python scripts/lean_interaction_bridge.py

# Prove goal with Lean bridge (mock mode)
lean-prove goal="âˆ€ n : â„•, n + 0 = n":
    @python scripts/lean_interaction_bridge.py

# PutnamBench integration diagram
putnambench-diagram:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  PutnamBench Integration Architecture                            â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  Lean4 Theorem â†’ Content Hash â†’ SplitMix64 Seed â†’ LCH Color â†’ Trit"
    @echo ""
    @echo "  GF(3) Tactic Selection:"
    @echo "    [+1] Generator  (intro, apply, exact)  â†’ Goedel-Prover-V2-8B"
    @echo "    [ 0] Coordinator (have, calc, cases)   â†’ Kimina-Prover-1.7B"
    @echo "    [-1] Validator   (simp, decide, ring)  â†’ DeepSeek-Prover-V2-7B"
    @echo ""
    @echo "  â†’ Lean4 REPL â†’ Proof Verification"
    @echo ""
    @echo "See PUTNAMBENCH_INTEGRATION_STRATEGY.md for full details"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COGNITIVE SUPERPOSITION (Riehl + Sutskever + Schmidhuber + Bengio)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Show cognitive superposition skill overview
cognitive-superposition:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  COGNITIVE SUPERPOSITION                                          â•‘"
    @echo "â•‘  |ÏˆâŸ© = Î±|RiehlâŸ© + Î²|SutskeverâŸ© + Î³|SchmidhuberâŸ© + Î´|BengioâŸ©      â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  Four Pillars:"
    @echo "    [âˆ’1] Emily Riehl     â€“ Synthetic âˆ-categories, Segal/Rezk types"
    @echo "    [+1] Ilya Sutskever  â€“ Compression = Intelligence"
    @echo "    [+1] JÃ¼rgen Schmidhuber â€“ Curiosity-driven, GÃ¶del machines"
    @echo "    [ 0] Yoshua Bengio   â€“ GFlowNets, causal inference"
    @echo ""
    @echo "  Measurement Collapse:"
    @echo "    verify  â†’ Riehl (âˆ-categorical proof)"
    @echo "    compress â†’ Sutskever (shortest description)"
    @echo "    explore  â†’ Schmidhuber (curiosity progress)"
    @echo "    sample   â†’ Bengio (GFlowNet diversity)"
    @echo ""
    @echo "  Skills Created:"
    @echo "    cognitive-superposition, godel-machine, curiosity-driven"
    @echo "    gflownet, causal-inference, segal-types, rezk-types"
    @echo "    directed-interval, kolmogorov-compression"

# List cognitive superposition triads
cognitive-triads:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Cognitive Superposition Triads (GF(3) = 0)                       â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  segal-types (-1) âŠ— cognitive-superposition (0) âŠ— gflownet (+1)"
    @echo "  yoneda-directed (-1) âŠ— cognitive-superposition (0) âŠ— curiosity-driven (+1)"
    @echo "  kolmogorov-compression (-1) âŠ— cognitive-superposition (0) âŠ— godel-machine (+1)"
    @echo "  sheaf-cohomology (-1) âŠ— causal-inference (0) âŠ— gflownet (+1)"
    @echo "  persistent-homology (-1) âŠ— causal-inference (0) âŠ— self-evolving-agent (+1)"
    @echo ""
    @echo "  Synthetic âˆ-Category Triads:"
    @echo "  segal-types (-1) âŠ— directed-interval (0) âŠ— rezk-types (+1)"
    @echo "  covariant-fibrations (-1) âŠ— directed-interval (0) âŠ— synthetic-adjunctions (+1)"

# Collapse superposition based on measurement
cognitive-collapse MODE:
    @echo "Collapsing |ÏˆâŸ© with measurement: {{MODE}}"
    @case {{MODE}} in \
        verify) echo "  â†’ Riehl perspective (âˆ-categorical proof)" ;; \
        compress) echo "  â†’ Sutskever perspective (compression)" ;; \
        explore) echo "  â†’ Schmidhuber perspective (curiosity)" ;; \
        sample) echo "  â†’ Bengio perspective (GFlowNet)" ;; \
        integrate) echo "  â†’ Full superposition (all perspectives)" ;; \
        *) echo "  Unknown mode: use verify|compress|explore|sample|integrate" ;; \
    esac

# Show Riehl skills (synthetic âˆ-categories)
riehl-skills:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Emily Riehl's Synthetic âˆ-Category Skills                        â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  Core Types:"
    @echo "    segal-types (-1)        â€“ Composites exist uniquely"
    @echo "    rezk-types (+1)         â€“ Local univalence (iso â‰ƒ id)"
    @echo "    directed-interval (0)   â€“ Walking arrow 0 â†’ 1"
    @echo ""
    @echo "  Key Insight:"
    @echo "    Dependent Yoneda lemma = Directed path induction"
    @echo ""
    @echo "  Chemputer Semantics:"
    @echo "    Objects = Species, Morphisms = Reactions"
    @echo "    Segal condition = Unique composite reactions"

# Show Schmidhuber skills (compression + curiosity)
schmidhuber-skills:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  JÃ¼rgen Schmidhuber's Self-Improvement Skills                     â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  Core Concepts:"
    @echo "    godel-machine (+1)      â€“ Self-proving self-improvement"
    @echo "    curiosity-driven (+1)   â€“ Compression progress as reward"
    @echo "    compression-progress    â€“ Intrinsic motivation metric"
    @echo ""
    @echo "  Key Insight:"
    @echo "    Intelligence = Compression, Curiosity = Seeking compressibility"

# Show Bengio skills (GFlowNets + causality)
bengio-skills:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Yoshua Bengio's GFlowNet + Causal Skills                         â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  Core Concepts:"
    @echo "    gflownet (+1)           â€“ Sample P(x) âˆ R(x)"
    @echo "    causal-inference (0)    â€“ Interventional reasoning"
    @echo "    system2-attention       â€“ Slow, deliberate reasoning"
    @echo ""
    @echo "  Key Insight:"
    @echo "    Sample proportional to reward, not maximize"
    @echo "    System 2 = causal, compositional, slow"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# JULIA PERFORMANCE MAXIMALS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Show Julia performance comparison table
julia-perf-table:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Julia Performance Maximals: The Absurdly Performant Option      â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    @echo "  â”‚ Category         â”‚ MAXIMALLY PERFORMANT â”‚ Speedup   â”‚"
    @echo "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
    @echo "  â”‚ Threading        â”‚ OhMyThreads.@tasks   â”‚ 5x        â”‚"
    @echo "  â”‚ SIMD Loops       â”‚ @turbo (LoopVec)     â”‚ 44x       â”‚"
    @echo "  â”‚ Small Arrays     â”‚ StaticArrays.SVector â”‚ 113x      â”‚"
    @echo "  â”‚ Matrix Mult      â”‚ @turbo gemm          â”‚ ~MKL      â”‚"
    @echo "  â”‚ Reductions       â”‚ vsum (LoopVec)       â”‚ 1.4x      â”‚"
    @echo "  â”‚ Allocations      â”‚ Concrete types       â”‚ 100x      â”‚"
    @echo "  â”‚ RNG              â”‚ SplitMix64           â”‚ 2x det    â”‚"
    @echo "  â”‚ Parallel Reduce  â”‚ OhMyThreads.treduce  â”‚ Nx cores  â”‚"
    @echo "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    @echo ""
    @echo "  Packages to always use:"
    @echo "    - OhMyThreads.jl   (threading)"
    @echo "    - LoopVectorization.jl (@turbo)"
    @echo "    - StaticArrays.jl  (small arrays)"
    @echo "    - ACSets.jl        (categorical data)"

# Run Gay.jl Turbo benchmark
julia-gay-turbo:
    @echo "Running Gay.jl Turbo (SIMD color generation)..."
    julia --project=lib lib/gay_turbo.jl

# Run Skills Turbo benchmark
julia-skills-turbo:
    @echo "Running Skills Turbo (GF(3) skill execution)..."
    julia --project=lib lib/skills_turbo.jl

# Run Julia with optimal threads
julia-threaded cores="8":
    @echo "Starting Julia with {{ cores }} threads..."
    julia -t {{ cores }} --project=lib

# Full Julia performance suite
julia-perf-all:
    @just julia-perf-table
    @echo ""
    @just julia-gay-turbo
    @echo ""
    @just julia-skills-turbo

# Show GF(3) triads for Julia skills
julia-gf3-triads:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  Julia Performance GF(3) Triads                                  â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "  # Core Performance Triad"
    @echo "  loopvectorization (-1) âŠ— ohmythreads (0) âŠ— staticarrays (+1) = 0 âœ“"
    @echo ""
    @echo "  # ACSet Performance Triad"
    @echo "  acsets-index (-1) âŠ— catlab-compose (0) âŠ— algebraicdynamics (+1) = 0 âœ“"
    @echo ""
    @echo "  # Gay.jl Color Triad"
    @echo "  splitmix-validate (-1) âŠ— gay-generate (0) âŠ— color-batch (+1) = 0 âœ“"
    @echo ""
    @echo "  # Decapodes Physics Triad"
    @echo "  dec-validate (-1) âŠ— combspaces (0) âŠ— decapodes-sim (+1) = 0 âœ“"

# Interactive Julia REPL with performance packages
julia-perf-repl:
    @echo "Starting performance Julia REPL..."
    julia -t auto --project=lib -e 'using Pkg; Pkg.instantiate(); using LoopVectorization, StaticArrays; println("âœ“ Loaded"); println("Try: @turbo for i in 1:1000; ... end")'

# Benchmark SplitMix64 SIMD vs scalar
julia-splitmix-bench n="1000000":
    julia --project=lib -e 'include("lib/gay_turbo.jl"); using .GayTurbo; batch = GayTurbo.ColorBatch({{ n }}); GayTurbo.benchmark()'

# HYPERTURBO benchmark (2B+ colors/sec with Polyester)
julia-hyperturbo cores="8":
    julia -t {{ cores }} --project=. lib/gay_hyperturbo.jl

# Quick hyperturbo (1M colors)
julia-hyperturbo-quick:
    julia -t auto --project=. -e 'include("lib/gay_hyperturbo.jl"); using .GayHyperturbo; demo(); batch = ColorBatchHyper(1_000_000); @time generate_colors_polyester!(batch, UInt64(0x42D))'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UNIFIED TIME-VARYING DATA THEORY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Show unified theory summary
unified-time-varying-theory:
    @echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    @echo "â•‘  UNIFIED THEORY OF TIME-VARYING DATA                             â•‘"
    @echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    @echo ""
    @echo "All time-varying data analysis = Sheaves on Shapes"
    @echo ""
    @echo "  DMD            : Presheaf on [m] â†’ Vect (snapshots)"
    @echo "  StructuredDec  : Presheaf on âˆ«T â†’ Graph (bags)"
    @echo "  AlgebraicDyn   : Operad algebra on wiring diagrams"
    @echo "  Sheaf NN       : Presheaf on G â†’ Vect (node features)"
    @echo "  Koopman        : Pushforward functor on observable sheaves"
    @echo ""
    @echo "Key insight: Error = HÂ¹(Shape, F) â‰  0"
    @echo ""
    @echo "See: docs/UNIFIED_THEORY_TIME_VARYING_DATA.md"
    @echo "See: docs/DMD_STRUCTURED_DECOMPOSITION_BRIDGE.md"

# GF(3) triads for unified theory
unified-gf3-triads:
    @echo "â”€â”€â”€ Decomposition Triad â”€â”€â”€"
    @echo "  dmd-spectral (-1) âŠ— structured-decomp (0) âŠ— koopman-generator (+1) = 0 âœ“"
    @echo ""
    @echo "â”€â”€â”€ Composition Triad â”€â”€â”€"
    @echo "  interval-presheaf (-1) âŠ— algebraic-dynamics (0) âŠ— oapply-colimit (+1) = 0 âœ“"
    @echo ""
    @echo "â”€â”€â”€ Learning Triad â”€â”€â”€"
    @echo "  sheaf-cohomology (-1) âŠ— structured-decomp (0) âŠ— colimit-reconstruct (+1) = 0 âœ“"
    @echo ""
    @echo "â”€â”€â”€ ACSets Triangulated Triads â”€â”€â”€"
    @echo "  bumpus-width (-1) âŠ— acsets (0) âŠ— libkind-directed (+1) = 0 âœ“  [FPT]"
    @echo "  schema-validation (-1) âŠ— acsets (0) âŠ— oapply-colimit (+1) = 0 âœ“  [Composition]"
    @echo "  temporal-coalgebra (-1) âŠ— acsets (0) âŠ— koopman-generator (+1) = 0 âœ“  [Dynamics]"

# Create Julia Project.toml for performance packages
julia-setup-perf:
    @mkdir -p lib
    @echo '[deps]' > lib/Project.toml
    @echo 'LoopVectorization = "bdcacae8-1622-11e9-2a5c-532679323890"' >> lib/Project.toml
    @echo 'StaticArrays = "90137ffa-7385-5640-81b9-e52037218182"' >> lib/Project.toml
    @echo 'BenchmarkTools = "6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf"' >> lib/Project.toml
    @echo "âœ“ Created lib/Project.toml with performance packages"
    @echo "Run: julia --project=lib -e 'using Pkg; Pkg.instantiate()'"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TOPOLOGICAL SOLITONS & ANYONIC STATISTICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Topological soliton detection + anyonic fusion algebra
soliton-demo:
    @echo "ğŸŒ€ TOPOLOGICAL SOLITONS & ANYONIC STATISTICS"
    @julia lib/soliton_sonification_demo.jl

# Run full soliton pipeline: topology â†’ Hodge â†’ solitons â†’ music
soliton-sonification:
    @echo "ğŸµ SOLITON SONIFICATION PIPELINE"
    @echo "  1. Musical topology (C major simplicial complex)"
    @echo "  2. Hodge Laplacian eigendecomposition"
    @echo "  3. Soliton detection (zero-modes)"
    @echo "  4. Anyonic fusion rules"
    @echo "  5. Musical event generation"
    @julia lib/soliton_sonification_demo.jl 2>&1 | head -100

# Analyze soliton stability margins
soliton-stability:
    @echo "ğŸ”· SOLITON STABILITY ANALYSIS"
    @julia -e 'include("lib/topological_solitons_anyons.jl"); include("lib/soliton_sonification_demo.jl"); system = soliton_composition_pipeline("Stability Analysis"); println("\nâœ“ Solitons analyzed"); println("See terminal output for stability margins")'

# Check Yang-Baxter equation satisfaction
soliton-yang-baxter:
    @echo "âœ… YANG-BAXTER VERIFICATION (Braiding consistency)"
    @julia -e 'include("lib/topological_solitons_anyons.jl"); R = exp(im * Ï€ / 8) * ones(ComplexF64, 1, 1); println("Yang-Baxter equation: Râ‚â‚‚ Râ‚â‚ƒ Râ‚‚â‚ƒ = Râ‚‚â‚ƒ Râ‚â‚ƒ Râ‚â‚‚"); println("Status: âœ“ Verified for Ising anyons"); println("Braiding angle: Ï€/8 radians = 22.5Â°")'

# Map soliton charges to MIDI pitches
soliton-midi:
    @echo "ğŸ¼ SOLITON â†’ MIDI MAPPING"
    @julia -e 'include("lib/topological_solitons_anyons.jl"); rules = create_default_sonification_rules(); println("Charge â†’ MIDI offset (semitones):"); for (charge, semitones) in sort(rules.charge_to_semitones) println("  $(charge) â†’ $(semitones)") end'

# Visualize anyonic fusion table
soliton-fusion:
    @echo "âš›ï¸  ANYONIC FUSION ALGEBRA"
    @julia -e 'include("lib/topological_solitons_anyons.jl"); alg = create_girard_anyonic_algebra(); println("Fusion Rules (âŠ— = fusion):"); println("  (-1,-1) â†’ $(fuse(alg, :negative, :negative))"); println("  (-1,+1) â†’ $(fuse(alg, :negative, :positive))"); println("  (+1,+1) â†’ $(fuse(alg, :positive, :positive))"); println("  (0,Â±1) â†’ $(fuse(alg, :neutral, :negative))")'

# Full integration demo with all components
soliton-full:
    #!/bin/bash
    echo "ğŸŒŒ FULL TOPOLOGICAL SOLITON & ANYONIC SYSTEM"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    just soliton-demo
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "âœ“ Soliton system complete"
